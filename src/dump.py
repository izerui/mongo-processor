#!/usr/bin/env python3
"""
æ•°æ®åº“å¯¼å‡ºç±» - æ”¯æŒåˆ†ç‰‡å¯¼å‡º
é›†æˆäº†åˆ†ç‰‡åˆ¤æ–­ã€èŒƒå›´è®¡ç®—å’Œå¯¼å‡ºé€»è¾‘
"""
import math
import os
import shutil
from concurrent.futures import ThreadPoolExecutor
from typing import List

from bson import ObjectId

from base import MyMongo, MongoConfig, ObjectIdRange
from src.base import GlobalConfig


class MyDump(MyMongo):
    """
    æŒ‰æ•°æ®åº“æ•´ä½“å¯¼å‡ºï¼Œæ”¯æŒå¤§collectionåˆ†ç‰‡
    """

    def __init__(self, mongo: MongoConfig, global_config: GlobalConfig):
        super().__init__(mongo, global_config)

    def export_db(self, database: str):
        """
        æŒ‰æ•°æ®åº“æ•´ä½“å¯¼å‡ºï¼Œæ”¯æŒå¤§collectionè‡ªåŠ¨åˆ†ç‰‡
        :param database: æ•°æ®åº“å
        :return: å¯¼å‡ºçš„æ•°æ®åº“ç›®å½•è·¯å¾„
        """
        try:
            print(f"ğŸš€ å¼€å§‹å¯¼å‡ºæ•°æ®åº“: {database}")

            if self.global_config.enable_sharding:
                return self._export_db_with_sharding(database)
            else:
                return self._export_db_normal(database)

        except Exception as e:
            print(f'âŒ å¯¼å‡ºæ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise

    def _export_db_with_sharding(self, database: str):
        """
        æ”¯æŒåˆ†ç‰‡çš„æ•°æ®åº“å¯¼å‡º - ä½¿ç”¨å¿«é€Ÿç»Ÿè®¡ä¿¡æ¯ä¼˜åŒ–åˆ¤æ–­
        """

        try:
            # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰collection
            collections = self.get_database_collections(database)
            if not collections:
                print(f"âš ï¸ æ•°æ®åº“ {database} ä¸­æ²¡æœ‰collection")
                return os.path.join(self.global_config.dump_root_path, database)

            # è¿‡æ»¤å¿½ç•¥çš„é›†åˆ
            filtered_collections = []
            ignored_collections = []
            for collection_name in collections:
                full_name = f"{database}.{collection_name}"
                if full_name in self.global_config.ignore_collections:
                    ignored_collections.append(collection_name)
                else:
                    filtered_collections.append(collection_name)

            collections = filtered_collections

            if ignored_collections:
                print(f"ğŸš« æ•°æ®åº“ {database} å¿½ç•¥ {len(ignored_collections)} ä¸ªé›†åˆ: {ignored_collections}")

            if not collections:
                print(f"âš ï¸ æ•°æ®åº“ {database} ä¸­æ²¡æœ‰éœ€è¦å¯¼å‡ºçš„collection")
                return os.path.join(self.global_config.dump_root_path, database)

            print(f"ğŸ“Š æ•°æ®åº“ {database} åŒ…å« {len(collections)} ä¸ªéœ€è¦å¯¼å‡ºçš„collection")

            # ä½¿ç”¨å¿«é€Ÿç»Ÿè®¡ä¿¡æ¯åˆ†æå“ªäº›collectionéœ€è¦åˆ†ç‰‡
            large_collections = []
            small_collections = []

            # æ‰¹é‡è·å–æ‰€æœ‰é›†åˆçš„ç»Ÿè®¡ä¿¡æ¯
            collection_counts = self.get_collection_counts_fast(database)

            for collection_name in collections:
                count = collection_counts.get(collection_name, 0)
                if count >= self.global_config.min_documents_for_shard:
                    large_collections.append(collection_name)
                else:
                    small_collections.append(collection_name)

            # æ­¥éª¤1: ä½¿ç”¨excludeå‚æ•°å¯¼å‡ºæ‰€æœ‰éå¤§é›†åˆ
            if small_collections:
                print(f"ğŸ“¦ å¼€å§‹å¯¼å‡º {len(small_collections)} ä¸ªéå¤§é›†åˆ...")
                self._export_collections_with_exclude(database, large_collections)

            # æ­¥éª¤2: åˆ†ç‰‡å¯¼å‡ºæ‰€æœ‰å¤§é›†åˆï¼ˆä½¿ç”¨ç²¾ç¡®è®¡æ•°è®¡ç®—åˆ†ç‰‡ï¼‰
            if large_collections:
                print(f"ğŸ”„ å¼€å§‹åˆ†ç‰‡å¯¼å‡º {len(large_collections)} ä¸ªå¤§é›†åˆ...")
                with ThreadPoolExecutor(max_workers=self.global_config.numParallelCollections) as executor:
                    futures = []
                    for collection_name in large_collections:
                        # è·å–ç²¾ç¡®è®¡æ•°ç”¨äºåˆ†ç‰‡è®¡ç®—
                        db = self.client[database]
                        collection = db[collection_name]
                        exact_count = collection.count_documents({})

                        future = executor.submit(
                            self._export_collection_shards,
                            database, collection_name, exact_count
                        )
                        futures.append((future, collection_name))

                    for future, collection_name in futures:
                        try:
                            future.result()
                            print(f"âœ… å¤§é›†åˆ {collection_name} åˆ†ç‰‡å¯¼å‡ºå®Œæˆ")
                        except Exception as e:
                            print(f"âŒ å¤§é›†åˆ {collection_name} åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: {e}")
                            raise

            # æ•°æ®åº“å¯¼å‡ºå®Œæˆ
            return os.path.join(self.global_config.dump_root_path, database)

        except Exception as e:
            print(f'âŒ åˆ†ç‰‡å¯¼å‡ºæ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise

    def _export_collections_with_exclude(self, database: str, exclude_collections: List[str]):
        """ä½¿ç”¨excludeå‚æ•°å¯¼å‡ºé™¤æŒ‡å®šé›†åˆå¤–çš„æ‰€æœ‰é›†åˆ"""
        try:
            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo_config.username and self.mongo_config.password:
                auth_append = f'--username={self.mongo_config.username} --password="{self.mongo_config.password}" --authenticationDatabase=admin'

            # æ„å»ºexcludeå‚æ•°
            exclude_params = ''
            if exclude_collections and len(exclude_collections) > 0:
                exclude_params = ' '.join([f'--excludeCollection={col}' for col in exclude_collections])

            # æ„å»ºå¯¼å‡ºå‘½ä»¤ - å¯¼å‡ºæ•´ä¸ªæ•°æ®åº“ä½†æ’é™¤å¤§é›†åˆ
            export_cmd = (
                f'{self.mongodump_exe} '
                f'--host="{self.mongo_config.host}:{self.mongo_config.port}" '
                f'--db={database} '
                f'--out={self.global_config.dump_root_path} '
                f'--numParallelCollections={self.global_config.numParallelCollections} '
                f'{exclude_params} '
                f'{auth_append}'
            )

            print(f"ğŸ“¦ å¯¼å‡ºéå¤§é›†åˆ: æ’é™¤ {len(exclude_collections)} ä¸ªé›†åˆ")
            self.exe_command(export_cmd, timeout=None)

        except Exception as e:
            print(f'âŒ å¯¼å‡ºéå¤§é›†åˆå¤±è´¥: {e}')
            raise

    def _export_collection_shards(self, db_name: str, collection_name: str, exact_count: int = None):
        """åˆ†ç‰‡å¯¼å‡ºå•ä¸ªcollectionï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•å’Œé‡å‘½åæœºåˆ¶"""
        try:
            # è®¡ç®—åˆ†ç‰‡æ•°é‡ï¼ˆä½¿ç”¨ç²¾ç¡®è®¡æ•°ï¼‰
            if exact_count is None:
                db = self.client[db_name]
                exact_count = db[collection_name].count_documents({})

            shard_count = self._calculate_optimal_shard_count(db_name, collection_name, exact_count)

            # è·å–åˆ†ç‰‡èŒƒå›´
            ranges = self._get_collection_objectid_ranges(db_name, collection_name, shard_count, exact_count)
            if not ranges:
                print(f"âš ï¸ æ— æ³•è·å–é›†åˆ {db_name}.{collection_name} çš„åˆ†ç‰‡èŒƒå›´ï¼Œä½¿ç”¨å¸¸è§„å¯¼å‡º")
                return self._export_collection_normal(db_name, collection_name)

            print(f"ğŸ”„ å¼€å§‹åˆ†ç‰‡å¯¼å‡º {db_name}.{collection_name}ï¼Œåˆ†ç‰‡æ•°: {len(ranges)}ï¼Œæ–‡æ¡£æ•°: {exact_count:,}")

            # åˆ›å»ºåˆ†ç‰‡å¯¼å‡ºç›®å½•ç»“æ„: dumps/{database}/{collection}_partXXX/
            # db_dumps_dir = os.path.join(self.global_config.dump_root_path, db_name)
            # os.makedirs(db_dumps_dir, exist_ok=True)

            # å¹¶å‘å¯¼å‡ºåˆ†ç‰‡ï¼ˆå¹¶å‘åº¦=åˆ†ç‰‡æ•°ï¼‰
            with ThreadPoolExecutor(max_workers=len(ranges)) as executor:
                futures = []
                for i, obj_range in enumerate(ranges):
                    future = executor.submit(
                        self._export_single_shard,
                        db_name, collection_name, i, obj_range
                    )
                    futures.append(future)

                for future in futures:
                    try:
                        future.result()
                    except Exception as e:
                        print(f"âŒ åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: {e}")
                        raise

            # æ•°æ®åº“ç›®å½•
            db_dir = os.path.join(self.global_config.dump_root_path, db_name)
            os.makedirs(db_dir, exist_ok=True)

            # ä¿å­˜åˆ†ç‰‡å…ƒæ•°æ®åˆ°æ•°æ®åº“ç›®å½•
            # self._save_shard_metadata(db_dir, db_name, collection_name, ranges)

            print(f"ğŸ‰ é›†åˆ {db_name}.{collection_name} åˆ†ç‰‡å¯¼å‡ºå®Œæˆï¼Œå…± {len(ranges)} ä¸ªåˆ†ç‰‡")

        except Exception as e:
            print(f"âŒ åˆ†ç‰‡å¯¼å‡ºé›†åˆ {db_name}.{collection_name} å¤±è´¥: {e}")
            raise

    def _export_single_shard(self, db_name: str, collection_name: str, shard_idx: int, obj_range: ObjectIdRange):
        """å¯¼å‡ºå•ä¸ªåˆ†ç‰‡åˆ°æŒ‡å®šç›®å½•"""
        try:
            # æ„å»ºåˆ†ç‰‡ç›®å½•åå’Œæ–‡ä»¶å
            part_suffix = f"_part{shard_idx + 1:03d}"
            collection_dir_name = f"{collection_name}{part_suffix}"
            part_dir = os.path.join(self.global_config.dump_root_path, db_name, collection_dir_name)
            os.makedirs(part_dir, exist_ok=True)

            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query_dict = obj_range.to_query()

            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo_config.username and self.mongo_config.password:
                auth_append = f'--username={self.mongo_config.username} --password="{self.mongo_config.password}" --authenticationDatabase=admin'

            # æ„å»ºå¯¼å‡ºå‘½ä»¤ - å¯¼å‡ºåˆ°åˆ†ç‰‡ç›®å½•
            export_cmd = (
                f'{self.mongodump_exe} '
                f'--host="{self.mongo_config.host}:{self.mongo_config.port}" '
                f'--db={db_name} '
                f'--collection={collection_name} '
                f'--out={part_dir} '
                f'{auth_append}'
            )

            # ä¿®å¤æŸ¥è¯¢æ¡ä»¶æ ¼å¼
            if query_dict:
                # ä½¿ç”¨æ­£ç¡®çš„Extended JSONæ ¼å¼å¤„ç†ObjectId
                query_parts = []
                if '_id' in query_dict:
                    id_query = query_dict['_id']
                    if '$gte' in id_query:
                        query_parts.append(f'"_id":{{"$gte":{{"$oid":"{str(id_query["$gte"])}"}}}}')
                    if '$lt' in id_query:
                        query_parts.append(f'"_id":{{"$lt":{{"$oid":"{str(id_query["$lt"])}"}}}}')

                if query_parts:
                    query_str = "{" + ",".join(query_parts) + "}"
                    export_cmd += f' --query=\'{query_str}\''

            # æ‰§è¡Œåˆ†ç‰‡å¯¼å‡º
            self.exe_command(export_cmd, timeout=None)

            # éªŒè¯åˆ†ç‰‡ç›®å½•ä¸­çš„å¯¼å‡ºç»“æœ
            collection_bson = os.path.join(part_dir, db_name, f"{collection_name}.bson")
            collection_metadata = os.path.join(part_dir, db_name, f"{collection_name}.metadata.json")

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            if not os.path.exists(collection_bson):
                print(f"âŒ åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {collection_bson}")
                # æ£€æŸ¥åˆ†ç‰‡ç›®å½•å†…å®¹
                if os.path.exists(part_dir):
                    files = os.listdir(part_dir)
                    print(f"ğŸ“ åˆ†ç‰‡ç›®å½•å†…å®¹: {files}")
                raise Exception(f"åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {collection_bson}")

            # æ„å»ºç›®æ ‡è·¯å¾„ï¼ˆç§»åŠ¨åˆ°å¤–å±‚ os.path.join(dump_root_path, db_name)ï¼‰
            target_dir = os.path.join(self.global_config.dump_root_path, db_name)
            target_bson = os.path.join(target_dir, f"{collection_name}{part_suffix}.bson")
            target_metadata = os.path.join(target_dir, f"{collection_name}{part_suffix}.metadata.json")

            # é‡å‘½åå¹¶ç§»åŠ¨æ–‡ä»¶
            if os.path.exists(collection_bson):
                shutil.move(collection_bson, target_bson)
            if os.path.exists(collection_metadata):
                shutil.move(collection_metadata, target_metadata)

            # åˆ é™¤ part_dir
            if os.path.exists(part_dir):
                shutil.rmtree(part_dir)

            print(f"âœ… åˆ†ç‰‡ {shard_idx + 1} å¯¼å‡ºå®Œæˆï¼Œæ–‡ä»¶å·²ç§»åŠ¨åˆ°: {target_dir}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºåˆ†ç‰‡ {shard_idx + 1} å¤±è´¥: {e}")
            raise

    def _export_collection_normal(self, db_name: str, collection_name: str):
        """å¸¸è§„å¯¼å‡ºå•ä¸ªcollectionï¼ˆä¸åˆ†ç‰‡ï¼‰"""
        try:
            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo_config.username and self.mongo_config.password:
                auth_append = f'--username={self.mongo_config.username} --password="{self.mongo_config.password}" --authenticationDatabase=admin'

            # æ„å»ºå¯¼å‡ºå‘½ä»¤
            export_cmd = (
                f'{self.mongodump_exe} '
                f'--host="{self.mongo_config.host}:{self.mongo_config.port}" '
                f'--db={db_name} '
                f'--collection={collection_name} '
                f'--out={self.global_config.dump_root_path} '
                f'{auth_append}'
            )

            # æ‰§è¡Œå¯¼å‡º
            self.exe_command(export_cmd, timeout=None)

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            output_bson = os.path.join(self.global_config.dump_root_path, db_name, f"{collection_name}.bson")
            if not os.path.exists(output_bson):
                raise Exception(f"å¸¸è§„å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {output_bson}")

            file_size = os.path.getsize(output_bson)
            if file_size == 0:
                raise Exception(f"å¸¸è§„å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸ºç©º {output_bson} (å¤§å°: {file_size} å­—èŠ‚)")

            print(f"âœ… å¸¸è§„å¯¼å‡ºæˆåŠŸ: {output_bson} (å¤§å°: {file_size} å­—èŠ‚)")

        except Exception as e:
            print(f"âŒ å¸¸è§„å¯¼å‡ºé›†åˆ {db_name}.{collection_name} å¤±è´¥: {e}")
            raise

    def _export_db_normal(self, database: str):
        """å¸¸è§„æ•°æ®åº“å¯¼å‡ºï¼ˆä¸ä½¿ç”¨åˆ†ç‰‡ï¼‰"""
        try:
            print(f"ğŸ“¦ å¼€å§‹å¸¸è§„å¯¼å‡ºæ•°æ®åº“: {database}")

            # è·å–éœ€è¦å¿½ç•¥çš„é›†åˆ
            ignore_collections_for_db = []
            for ignore_pattern in self.global_config.ignore_collections:
                if ignore_pattern.startswith(f"{database}."):
                    collection_name = ignore_pattern[len(database)+1:]
                    ignore_collections_for_db.append(collection_name)

            if ignore_collections_for_db:
                print(f"ğŸš« å¿½ç•¥é›†åˆ: {ignore_collections_for_db}")

            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo_config.username and self.mongo_config.password:
                auth_append = f'--username={self.mongo_config.username} --password="{self.mongo_config.password}" --authenticationDatabase=admin'
            pass
            # æ„å»ºå¯¼å‡ºå‘½ä»¤ - ç›´æ¥å¯¼å‡ºåˆ°dumps/{database}/
            exclude_params = ''
            if ignore_collections_for_db:
                exclude_params = ' '.join([f'--excludeCollection={col}' for col in ignore_collections_for_db])

            export_cmd = (
                f'{self.mongodump_exe} '
                f'--host="{self.mongo_config.host}:{self.mongo_config.port}" '
                f'--db={database} '
                f'--out={self.global_config.dump_root_path} '
                f'{exclude_params} '
                f'{auth_append}'
            )

            # æ‰§è¡Œå¯¼å‡º
            self.exe_command(export_cmd, timeout=None)

            # éªŒè¯æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æ–‡ä»¶
            db_dir = os.path.join(self.global_config.dump_root_path, database)
            if not os.path.exists(db_dir):
                raise Exception(f"æ•°æ®åº“å¯¼å‡ºå¤±è´¥: ç›®å½•ä¸å­˜åœ¨ {db_dir}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å¯¼å‡ºæ–‡ä»¶
            has_files = False
            for filename in os.listdir(db_dir):
                if filename.endswith('.bson'):
                    file_path = os.path.join(db_dir, filename)
                    file_size = os.path.getsize(file_path)
                    if file_size > 0:
                        has_files = True
                        print(f"âœ… æ•°æ®åº“å¯¼å‡ºåŒ…å«: {filename} (å¤§å°: {file_size} å­—èŠ‚)")

            if not has_files:
                raise Exception(f"æ•°æ®åº“å¯¼å‡ºå¤±è´¥: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¯¼å‡ºæ–‡ä»¶")

            # æ•°æ®åº“å¯¼å‡ºå®Œæˆ
            return db_dir

        except Exception as e:
            print(f'âŒ å¸¸è§„å¯¼å‡ºæ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise

    def _calculate_optimal_shard_count(self, database: str, collection_name: str, doc_count: int = None) -> int:
        """è®¡ç®—æœ€ä¼˜åˆ†ç‰‡æ•°é‡ï¼ˆä½¿ç”¨ç²¾ç¡®è®¡æ•°ï¼‰"""
        try:
            if doc_count is None:
                db = self.client[database]
                collection = db[collection_name]
                doc_count = collection.count_documents({})

            # æ ¹æ®æ–‡æ¡£æ•°é‡è®¡ç®—åˆ†ç‰‡æ•°
            if doc_count < self.global_config.min_documents_for_shard:
                return 1

            # è®¡ç®—éœ€è¦çš„åˆ†ç‰‡æ•°ï¼ˆæ¯100ä¸‡æ–‡æ¡£ä¸€ä¸ªåˆ†ç‰‡ï¼‰
            needed_shards = max(1, min(
                math.ceil(doc_count / self.global_config.min_documents_for_shard),
                self.global_config.max_shard_count
            ))

            print(
                f"ğŸ“Š åˆ†ç‰‡è®¡ç®—: {doc_count:,} æ¡è®°å½• -> {needed_shards} ä¸ªåˆ†ç‰‡ (æœ€å¤§: {self.global_config.max_shard_count})")

            return needed_shards

        except Exception as e:
            print(f"âš ï¸ è®¡ç®—åˆ†ç‰‡æ•°é‡å¤±è´¥: {e}")
            return self.global_config.default_shard_count

    def _get_collection_objectid_ranges(self, db_name: str, collection_name: str, shard_count: int,
                                        doc_count: int = None) -> List[
        ObjectIdRange]:
        """è·å–collectionçš„ObjectIdåˆ†ç‰‡èŒƒå›´"""
        try:
            if shard_count <= 1:
                return []

            db = self.client[db_name]
            collection = db[collection_name]

            # å¦‚æœæä¾›äº†ç²¾ç¡®è®¡æ•°ä¸”åˆ†ç‰‡æ•°ä¸º1ï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨
            if doc_count is not None and shard_count <= 1:
                return []

            # è·å–æœ€å°å’Œæœ€å¤§çš„ObjectId
            min_doc = collection.find_one(sort=[("_id", 1)])
            max_doc = collection.find_one(sort=[("_id", -1)])

            if not min_doc or not max_doc:
                return []

            min_id = min_doc["_id"]
            max_id = max_doc["_id"]

            # å¦‚æœæœ€å°å’Œæœ€å¤§IDç›¸åŒï¼Œä¸éœ€è¦åˆ†ç‰‡
            if min_id == max_id:
                return []

            # è®¡ç®—æ¯ä¸ªåˆ†ç‰‡çš„èŒƒå›´
            ranges = []

            # æ£€æŸ¥ObjectIdç±»å‹
            try:
                min_str = str(min_id)
                max_str = str(max_id)

                # ObjectIdå­—ç¬¦ä¸²æ ¼å¼: 24ä¸ªåå…­è¿›åˆ¶å­—ç¬¦
                if len(min_str) != 24 or len(max_str) != 24:
                    return []

                min_int = int(min_str, 16)
                max_int = int(max_str, 16)
                total_range = max_int - min_int

                if total_range <= 0:
                    return []

            except ValueError as e:
                print(f"âš ï¸ åˆ†ç‰‡è°ƒè¯•: ObjectIdè½¬æ¢å¤±è´¥: {e}")
                return []

            shard_size = total_range // shard_count

            for i in range(shard_count):
                start_offset = i * shard_size
                end_offset = (i + 1) * shard_size if i < shard_count - 1 else total_range

                start_hex = hex(min_int + start_offset)[2:].zfill(24)
                end_hex = hex(min_int + end_offset)[2:].zfill(24)

                start_id = ObjectId(start_hex)
                if i == shard_count - 1:
                    end_id = None
                else:
                    end_id = ObjectId(end_hex)
                ranges.append(ObjectIdRange(start_id, end_id))

            return ranges

        except Exception as e:
            return []
