#!/usr/bin/env python3
"""
æ•°æ®åº“å¯¼å‡ºç±» - æ”¯æŒåˆ†ç‰‡å¯¼å‡º
é›†æˆäº†åˆ†ç‰‡åˆ¤æ–­ã€èŒƒå›´è®¡ç®—å’Œå¯¼å‡ºé€»è¾‘
"""
import os
import json
import math
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from pymongo import MongoClient
from pymongo.collection import Collection
from bson import ObjectId
import shutil

from base import Shell, Mongo, mongodump_exe, ObjectIdRange

from base import ShardConfig


class MyDump(Shell):
    """
    æŒ‰æ•°æ®åº“æ•´ä½“å¯¼å‡ºï¼Œæ”¯æŒå¤§collectionåˆ†ç‰‡
    """

    def __init__(self, mongo: Mongo, numParallelCollections: int = 4,
                 enable_sharding: bool = True, shard_config: Optional[ShardConfig] = None):
        super().__init__()
        self.mongo = mongo
        self.numParallelCollections = numParallelCollections
        self.enable_sharding = enable_sharding
        self.shard_config = shard_config or ShardConfig()
        self.client = None

    def export_db(self, database: str, dump_root_path: str):
        """
        æŒ‰æ•°æ®åº“æ•´ä½“å¯¼å‡ºï¼Œæ”¯æŒå¤§collectionè‡ªåŠ¨åˆ†ç‰‡
        :param database: æ•°æ®åº“å
        :param dump_root_path: å¯¼å‡ºæ ¹ç›®å½•
        :return: å¯¼å‡ºçš„æ•°æ®åº“ç›®å½•è·¯å¾„
        """
        try:
            print(f"ğŸš€ å¼€å§‹å¯¼å‡ºæ•°æ®åº“: {database}")

            if self.enable_sharding:
                return self._export_db_with_sharding(database, dump_root_path)
            else:
                return self._export_db_normal(database, dump_root_path)

        except Exception as e:
            print(f'âŒ å¯¼å‡ºæ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise

    def _export_db_with_sharding(self, database: str, dump_root_path: str):
        """
        æ”¯æŒåˆ†ç‰‡çš„æ•°æ®åº“å¯¼å‡º - ä½¿ç”¨ä¸´æ—¶ç›®å½•å’Œé‡å‘½åæœºåˆ¶
        """
        import shutil

        try:
            # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰collection
            collections = self._get_database_collections(database)
            if not collections:
                print(f"âš ï¸ æ•°æ®åº“ {database} ä¸­æ²¡æœ‰collection")
                return os.path.join(dump_root_path, database)

            print(f"ğŸ“Š æ•°æ®åº“ {database} åŒ…å« {len(collections)} ä¸ªcollection")

            # åˆ†æå“ªäº›collectionéœ€è¦åˆ†ç‰‡
            large_collections = []
            small_collections = []

            for collection_name in collections:
                if self._should_shard_collection(database, collection_name):
                    large_collections.append(collection_name)
                    print(f"ğŸ”„ Collection {collection_name} å°†ä½¿ç”¨åˆ†ç‰‡å¯¼å‡º")
                else:
                    small_collections.append(collection_name)
                    print(f"ğŸ“¦ Collection {collection_name} ä½¿ç”¨å¸¸è§„å¯¼å‡º")

            # æ­¥éª¤1: ä½¿ç”¨excludeå‚æ•°å¯¼å‡ºæ‰€æœ‰éå¤§é›†åˆ
            if small_collections:
                print(f"ğŸ“¦ å¼€å§‹å¯¼å‡º {len(small_collections)} ä¸ªéå¤§é›†åˆ...")
                self._export_collections_with_exclude(database, large_collections, dump_root_path)

            # æ­¥éª¤2: åˆ†ç‰‡å¯¼å‡ºæ‰€æœ‰å¤§é›†åˆ
            if large_collections:
                print(f"ğŸ”„ å¼€å§‹åˆ†ç‰‡å¯¼å‡º {len(large_collections)} ä¸ªå¤§é›†åˆ...")
                with ThreadPoolExecutor(max_workers=self.numParallelCollections) as executor:
                    futures = []
                    for collection_name in large_collections:
                        future = executor.submit(
                            self._export_collection_shards,
                            database, collection_name, dump_root_path
                        )
                        futures.append((future, collection_name))

                    for future, collection_name in futures:
                        try:
                            future.result()
                            print(f"âœ… å¤§é›†åˆ {collection_name} åˆ†ç‰‡å¯¼å‡ºå®Œæˆ")
                        except Exception as e:
                            print(f"âŒ å¤§é›†åˆ {collection_name} åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: {e}")
                            raise

            # æ•°æ®åº“å¯¼å‡ºå®Œæˆ
            return os.path.join(dump_root_path, database)

        except Exception as e:
            print(f'âŒ åˆ†ç‰‡å¯¼å‡ºæ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise
        finally:
            self._disconnect()

    def _export_collections_with_exclude(self, database: str, exclude_collections: List[str], dump_root_path: str):
        """ä½¿ç”¨excludeå‚æ•°å¯¼å‡ºé™¤æŒ‡å®šé›†åˆå¤–çš„æ‰€æœ‰é›†åˆ"""
        try:
            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo.username and self.mongo.password:
                auth_append = f'--username={self.mongo.username} --password="{self.mongo.password}" --authenticationDatabase=admin'
                # æ„å»ºexcludeå‚æ•°
                exclude_params = ''
                if exclude_collections and len(exclude_collections) > 0:
                    exclude_params = ' '.join([f'--excludeCollection={col}' for col in exclude_collections])

            # æ„å»ºå¯¼å‡ºå‘½ä»¤ - å¯¼å‡ºæ•´ä¸ªæ•°æ®åº“ä½†æ’é™¤å¤§é›†åˆ
            export_cmd = (
                f'{mongodump_exe} '
                f'--host="{self.mongo.host}:{self.mongo.port}" '
                f'--db={database} '
                f'--out={dump_root_path} '
                f'{exclude_params} '
                f'{auth_append}'
            )

            print(f"ğŸ“¦ å¯¼å‡ºéå¤§é›†åˆ: æ’é™¤ {len(exclude_collections)} ä¸ªé›†åˆ")
            self._exe_command(export_cmd)

        except Exception as e:
            print(f'âŒ å¯¼å‡ºéå¤§é›†åˆå¤±è´¥: {e}')
            raise

    def _export_collection_shards(self, db_name: str, collection_name: str, dump_root_path: str):
        """åˆ†ç‰‡å¯¼å‡ºå•ä¸ªcollectionï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•å’Œé‡å‘½åæœºåˆ¶"""
        try:
            # è®¡ç®—åˆ†ç‰‡æ•°é‡
            shard_count = self._calculate_optimal_shard_count(db_name, collection_name)

            # è·å–åˆ†ç‰‡èŒƒå›´
            ranges = self._get_collection_objectid_ranges(db_name, collection_name, shard_count)
            if not ranges:
                print(f"âš ï¸ æ— æ³•è·å–é›†åˆ {db_name}.{collection_name} çš„åˆ†ç‰‡èŒƒå›´ï¼Œä½¿ç”¨å¸¸è§„å¯¼å‡º")
                return self._export_collection_normal(db_name, collection_name, dump_root_path)

            print(f"ğŸ”„ å¼€å§‹åˆ†ç‰‡å¯¼å‡º {db_name}.{collection_name}ï¼Œåˆ†ç‰‡æ•°: {len(ranges)}")

            # åˆ›å»ºåˆ†ç‰‡å¯¼å‡ºç›®å½•ç»“æ„: dumps/{database}/{collection}_partXXX/
            dumps_dir = os.path.join(dump_root_path, db_name)
            os.makedirs(dumps_dir, exist_ok=True)

            # å¹¶å‘å¯¼å‡ºåˆ†ç‰‡ï¼ˆå¹¶å‘åº¦=åˆ†ç‰‡æ•°ï¼‰
            with ThreadPoolExecutor(max_workers=len(ranges)) as executor:
                futures = []
                for i, obj_range in enumerate(ranges):
                    future = executor.submit(
                        self._export_single_shard,
                        db_name, collection_name, dump_root_path, i, obj_range
                    )
                    futures.append(future)

                for future in futures:
                    try:
                        future.result()
                    except Exception as e:
                        print(f"âŒ åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: {e}")
                        raise

            # æ•°æ®åº“ç›®å½•
            db_dir = os.path.join(dump_root_path, 'dumps', db_name)
            os.makedirs(db_dir, exist_ok=True)

            # ä¿å­˜åˆ†ç‰‡å…ƒæ•°æ®åˆ°æ•°æ®åº“ç›®å½•
            # self._save_shard_metadata(db_dir, db_name, collection_name, ranges)

            print(f"ğŸ‰ é›†åˆ {db_name}.{collection_name} åˆ†ç‰‡å¯¼å‡ºå®Œæˆï¼Œå…± {len(ranges)} ä¸ªåˆ†ç‰‡")

        except Exception as e:
            print(f"âŒ åˆ†ç‰‡å¯¼å‡ºé›†åˆ {db_name}.{collection_name} å¤±è´¥: {e}")
            raise

    def _export_single_shard(self, db_name: str, collection_name: str,
                             dump_root_path: str, shard_idx: int, obj_range: ObjectIdRange):
        """å¯¼å‡ºå•ä¸ªåˆ†ç‰‡åˆ°æŒ‡å®šç›®å½•"""
        try:
            # æ„å»ºåˆ†ç‰‡ç›®å½•åå’Œæ–‡ä»¶å
            part_suffix = f"_part{shard_idx + 1:03d}"
            collection_dir_name = f"{collection_name}{part_suffix}"
            part_dir = os.path.join(dump_root_path, db_name, collection_dir_name)
            os.makedirs(part_dir, exist_ok=True)

            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query_dict = obj_range.to_query()
            query_json = json.dumps(query_dict, default=str) if query_dict else "{}"

            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo.username and self.mongo.password:
                auth_append = f'--username={self.mongo.username} --password="{self.mongo.password}" --authenticationDatabase=admin'

            # æ„å»ºå¯¼å‡ºå‘½ä»¤ - å¯¼å‡ºåˆ°åˆ†ç‰‡ç›®å½•
            export_cmd = (
                f'{mongodump_exe} '
                f'--host="{self.mongo.host}:{self.mongo.port}" '
                f'--db={db_name} '
                f'--collection={collection_name} '
                f'--out={part_dir} '
                f'{auth_append}'
            )

            # ä¿®å¤æŸ¥è¯¢æ¡ä»¶æ ¼å¼
            if query_dict:
                # ä½¿ç”¨æ­£ç¡®çš„Extended JSONæ ¼å¼å¤„ç†ObjectId
                query_parts = []
                if '_id' in query_dict:
                    id_query = query_dict['_id']
                    if '$gte' in id_query:
                        query_parts.append(f'"_id":{{"$gte":{{"$oid":"{str(id_query["$gte"])}"}}}}')
                    if '$lt' in id_query:
                        query_parts.append(f'"_id":{{"$lt":{{"$oid":"{str(id_query["$lt"])}"}}}}')

                if query_parts:
                    query_str = "{" + ",".join(query_parts) + "}"
                    export_cmd += f' --query=\'{query_str}\''

            # æ‰§è¡Œåˆ†ç‰‡å¯¼å‡º
            self._exe_command(export_cmd)

            # éªŒè¯åˆ†ç‰‡ç›®å½•ä¸­çš„å¯¼å‡ºç»“æœ
            collection_bson = os.path.join(part_dir, db_name, f"{collection_name}.bson")
            collection_metadata = os.path.join(part_dir, db_name, f"{collection_name}.metadata.json")

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            if not os.path.exists(collection_bson):
                print(f"âŒ åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {collection_bson}")
                # æ£€æŸ¥åˆ†ç‰‡ç›®å½•å†…å®¹
                if os.path.exists(part_dir):
                    files = os.listdir(part_dir)
                    print(f"ğŸ“ åˆ†ç‰‡ç›®å½•å†…å®¹: {files}")
                raise Exception(f"åˆ†ç‰‡å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {collection_bson}")

            # æ„å»ºç›®æ ‡è·¯å¾„ï¼ˆç§»åŠ¨åˆ°å¤–å±‚ os.path.join(dump_root_path, db_name)ï¼‰
            target_dir = os.path.join(dump_root_path, db_name)
            target_bson = os.path.join(target_dir, f"{collection_name}{part_suffix}.bson")
            target_metadata = os.path.join(target_dir, f"{collection_name}{part_suffix}.metadata.json")

            # é‡å‘½åå¹¶ç§»åŠ¨æ–‡ä»¶
            if os.path.exists(collection_bson):
                shutil.move(collection_bson, target_bson)
            if os.path.exists(collection_metadata):
                shutil.move(collection_metadata, target_metadata)

            # åˆ é™¤ part_dir
            if os.path.exists(part_dir):
                shutil.rmtree(part_dir)

            # ä¿®æ”¹åˆ†ç‰‡å…ƒæ•°æ®ï¼Œå°†é›†åˆåæ”¹ä¸ºå½“å‰åˆ†ç‰‡çš„æ–‡ä»¶å
            part_suffix = f"_part{shard_idx + 1:03d}"
            shard_collection_name = f"{collection_name}{part_suffix}"
            metadata_file = os.path.join(target_dir, f"{shard_collection_name}.metadata.json")

            if os.path.exists(metadata_file):
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)

                    # ä¿®æ”¹é›†åˆåç§°ä¸ºåˆ†ç‰‡æ–‡ä»¶å
                    metadata['collectionName'] = shard_collection_name

                    # ä¿®æ”¹indexesä¸­çš„nså­—æ®µ
                    if 'indexes' in metadata:
                        for index in metadata['indexes']:
                            if 'ns' in index:
                                index['ns'] = f"{db_name}.{shard_collection_name}"

                    with open(metadata_file, 'w', encoding='utf-8') as f:
                        json.dump(metadata, f, indent=2, ensure_ascii=False)

                    print(f"ğŸ“ å·²ä¿®æ”¹åˆ†ç‰‡å…ƒæ•°æ®: {metadata_file}ï¼Œé›†åˆåæ”¹ä¸º: {shard_collection_name}")
                except Exception as e:
                    print(f"âš ï¸ ä¿®æ”¹åˆ†ç‰‡å…ƒæ•°æ®å¤±è´¥: {e}")

            print(f"âœ… åˆ†ç‰‡ {shard_idx + 1} å¯¼å‡ºå®Œæˆï¼Œæ–‡ä»¶å·²ç§»åŠ¨åˆ°: {target_dir}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºåˆ†ç‰‡ {shard_idx + 1} å¤±è´¥: {e}")
            raise

    def _export_collection_normal(self, db_name: str, collection_name: str, dump_root_path: str):
        """å¸¸è§„å¯¼å‡ºå•ä¸ªcollectionï¼ˆä¸åˆ†ç‰‡ï¼‰"""
        try:
            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo.username and self.mongo.password:
                auth_append = f'--username={self.mongo.username} --password="{self.mongo.password}" --authenticationDatabase=admin'

            # æ„å»ºå¯¼å‡ºå‘½ä»¤
            export_cmd = (
                f'{mongodump_exe} '
                f'--host="{self.mongo.host}:{self.mongo.port}" '
                f'--db={db_name} '
                f'--collection={collection_name} '
                f'--out={dump_root_path} '
                f'{auth_append}'
            )

            # æ‰§è¡Œå¯¼å‡º
            self._exe_command(export_cmd)

            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            output_bson = os.path.join(dump_root_path, db_name, f"{collection_name}.bson")
            if not os.path.exists(output_bson):
                raise Exception(f"å¸¸è§„å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {output_bson}")

            file_size = os.path.getsize(output_bson)
            if file_size == 0:
                raise Exception(f"å¸¸è§„å¯¼å‡ºå¤±è´¥: æ–‡ä»¶ä¸ºç©º {output_bson} (å¤§å°: {file_size} å­—èŠ‚)")

            print(f"âœ… å¸¸è§„å¯¼å‡ºæˆåŠŸ: {output_bson} (å¤§å°: {file_size} å­—èŠ‚)")

        except Exception as e:
            print(f"âŒ å¸¸è§„å¯¼å‡ºé›†åˆ {db_name}.{collection_name} å¤±è´¥: {e}")
            raise

    def _save_shard_metadata(self, output_dir: str, db_name: str, collection_name: str, ranges: List[ObjectIdRange]):
        """ä¿å­˜åˆ†ç‰‡å…ƒæ•°æ®"""
        try:
            metadata = {
                "collection": collection_name,
                "shard_count": len(ranges),
                "created_at": datetime.now().isoformat(),
                "ranges": [
                    {
                        "shard_index": i,
                        "start_id": str(r.start_id) if r.start_id else None,
                        "end_id": str(r.end_id) if r.end_id else None
                    }
                    for i, r in enumerate(ranges)
                ]
            }

            db_dir = os.path.join(output_dir, db_name)
            metadata_file = os.path.join(db_dir, f"{collection_name}_shards.json")
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            print(f"ğŸ’¾ å·²ä¿å­˜åˆ†ç‰‡å…ƒæ•°æ®: {metadata_file}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜åˆ†ç‰‡å…ƒæ•°æ®å¤±è´¥: {e}")

    def _connect(self) -> bool:
        """å»ºç«‹MongoDBè¿æ¥"""
        try:
            if self.mongo.username and self.mongo.password:
                uri = f"mongodb://{self.mongo.username}:{self.mongo.password}@{self.mongo.host}:{self.mongo.port}/admin"
            else:
                uri = f"mongodb://{self.mongo.host}:{self.mongo.port}/"

            self.client = MongoClient(uri)
            return True
        except Exception as e:
            print(f"âŒ MongoDBè¿æ¥å¤±è´¥: {e}")
            return False

    def _disconnect(self):
        """æ–­å¼€MongoDBè¿æ¥"""
        if self.client:
            self.client.close()

    def _get_database_collections(self, database: str) -> List[str]:
        """è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰collectionåç§°"""
        try:
            if not self._connect():
                return []

            db = self.client[database]

            # è·å–æ‰€æœ‰collectionåç§°ï¼Œæ’é™¤ç³»ç»Ÿcollection
            collections = [name for name in db.list_collection_names()
                           if not name.startswith('system.')]

            return collections

        except Exception as e:
            print(f"âŒ è·å–æ•°æ®åº“ {database} collectionåˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _export_db_normal(self, database: str, dump_root_path: str):
        """å¸¸è§„æ•°æ®åº“å¯¼å‡ºï¼ˆä¸ä½¿ç”¨åˆ†ç‰‡ï¼‰"""
        try:
            print(f"ğŸ“¦ å¼€å§‹å¸¸è§„å¯¼å‡ºæ•°æ®åº“: {database}")

            # æ„å»ºè®¤è¯å‚æ•°
            auth_append = ''
            if self.mongo.username and self.mongo.password:
                auth_append = f'--username={self.mongo.username} --password="{self.mongo.password}" --authenticationDatabase=admin'

            # æ„å»ºå¯¼å‡ºå‘½ä»¤ - ç›´æ¥å¯¼å‡ºåˆ°dumps/{database}/
            export_cmd = (
                f'{mongodump_exe} '
                f'--host="{self.mongo.host}:{self.mongo.port}" '
                f'--db={database} '
                f'--out={dump_root_path} '
                f'{auth_append}'
            )

            # æ‰§è¡Œå¯¼å‡º
            self._exe_command(export_cmd)

            # éªŒè¯æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æ–‡ä»¶
            db_dir = os.path.join(dump_root_path, database)
            if not os.path.exists(db_dir):
                raise Exception(f"æ•°æ®åº“å¯¼å‡ºå¤±è´¥: ç›®å½•ä¸å­˜åœ¨ {db_dir}")

            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å¯¼å‡ºæ–‡ä»¶
            has_files = False
            for filename in os.listdir(db_dir):
                if filename.endswith('.bson'):
                    file_path = os.path.join(db_dir, filename)
                    file_size = os.path.getsize(file_path)
                    if file_size > 0:
                        has_files = True
                        print(f"âœ… æ•°æ®åº“å¯¼å‡ºåŒ…å«: {filename} (å¤§å°: {file_size} å­—èŠ‚)")

            if not has_files:
                raise Exception(f"æ•°æ®åº“å¯¼å‡ºå¤±è´¥: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¯¼å‡ºæ–‡ä»¶")

            # æ•°æ®åº“å¯¼å‡ºå®Œæˆ
            return db_dir

        except Exception as e:
            print(f'âŒ å¸¸è§„å¯¼å‡ºæ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise

    def _should_shard_collection(self, database: str, collection_name: str) -> bool:
        """åˆ¤æ–­collectionæ˜¯å¦éœ€è¦åˆ†ç‰‡å¯¼å‡º"""
        try:
            if not self._connect():
                return False

            db = self.client[database]
            collection = db[collection_name]

            # è·å–æ–‡æ¡£æ•°é‡
            doc_count = collection.estimated_document_count()

            # åªæœ‰å¤§é›†åˆæ‰æ˜¾ç¤ºæ¡ç›®æ•°
            is_large = doc_count >= self.shard_config.min_documents_for_shard
            if is_large:
                print(f"ğŸ“Š å¤§é›†åˆ {database}.{collection_name}: {doc_count:,} æ¡è®°å½•")

            return is_large

        except Exception as e:
            print(f"âš ï¸ åˆ¤æ–­collection {database}.{collection_name} åˆ†ç‰‡éœ€æ±‚å¤±è´¥: {e}")
            return False

    def _calculate_optimal_shard_count(self, db_name: str, collection_name: str) -> int:
        """è®¡ç®—æœ€ä¼˜çš„åˆ†ç‰‡æ•°é‡"""
        try:
            if not self._connect():
                return 1

            db = self.client[db_name]
            collection = db[collection_name]

            # è·å–æ–‡æ¡£æ•°é‡
            doc_count = collection.estimated_document_count()

            # æ ¹æ®æ–‡æ¡£æ•°é‡è®¡ç®—åˆ†ç‰‡æ•°
            if doc_count < self.shard_config.min_documents_for_shard:
                return 1

            # è®¡ç®—éœ€è¦çš„åˆ†ç‰‡æ•°ï¼ˆæ¯100ä¸‡æ–‡æ¡£ä¸€ä¸ªåˆ†ç‰‡ï¼‰
            needed_shards = max(1, min(
                math.ceil(doc_count / self.shard_config.min_documents_for_shard),
                self.shard_config.max_shard_count
            ))

            print(
                f"ğŸ“Š åˆ†ç‰‡è®¡ç®—: {doc_count:,} æ¡è®°å½• -> {needed_shards} ä¸ªåˆ†ç‰‡ (æœ€å¤§: {self.shard_config.max_shard_count})")

            return needed_shards

        except Exception as e:
            print(f"âš ï¸ è®¡ç®—åˆ†ç‰‡æ•°é‡å¤±è´¥: {e}")
            return self.shard_config.default_shard_count

    def _get_collection_objectid_ranges(self, db_name: str, collection_name: str, shard_count: int) -> List[
        ObjectIdRange]:
        """è·å–collectionçš„ObjectIdåˆ†ç‰‡èŒƒå›´"""
        try:
            if not self._connect() or shard_count <= 1:
                return []

            db = self.client[db_name]
            collection = db[collection_name]

            # è·å–æœ€å°å’Œæœ€å¤§çš„ObjectId
            min_doc = collection.find_one(sort=[("_id", 1)])
            max_doc = collection.find_one(sort=[("_id", -1)])

            if not min_doc or not max_doc:
                return []

            min_id = min_doc["_id"]
            max_id = max_doc["_id"]

            # å¦‚æœæœ€å°å’Œæœ€å¤§IDç›¸åŒï¼Œä¸éœ€è¦åˆ†ç‰‡
            if min_id == max_id:
                return []

            # è®¡ç®—æ¯ä¸ªåˆ†ç‰‡çš„èŒƒå›´
            ranges = []

            # æ£€æŸ¥ObjectIdç±»å‹
            try:
                min_str = str(min_id)
                max_str = str(max_id)

                # ObjectIdå­—ç¬¦ä¸²æ ¼å¼: 24ä¸ªåå…­è¿›åˆ¶å­—ç¬¦
                if len(min_str) != 24 or len(max_str) != 24:
                    return []

                min_int = int(min_str, 16)
                max_int = int(max_str, 16)
                total_range = max_int - min_int

                if total_range <= 0:
                    return []

            except ValueError as e:
                print(f"âš ï¸ åˆ†ç‰‡è°ƒè¯•: ObjectIdè½¬æ¢å¤±è´¥: {e}")
                return []

            shard_size = total_range // shard_count

            for i in range(shard_count):
                start_offset = i * shard_size
                end_offset = (i + 1) * shard_size if i < shard_count - 1 else total_range

                start_hex = hex(min_int + start_offset)[2:].zfill(24)
                end_hex = hex(min_int + end_offset)[2:].zfill(24)

                start_id = ObjectId(start_hex)
                if i == shard_count - 1:
                    end_id = None
                else:
                    end_id = ObjectId(end_hex)
                ranges.append(ObjectIdRange(start_id, end_id))

            return ranges

        except Exception as e:
            return []

    def get_shard_config(self) -> ShardConfig:
        """è·å–åˆ†ç‰‡é…ç½®"""
        return self.shard_config
