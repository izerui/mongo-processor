import os
from concurrent.futures import ThreadPoolExecutor, as_completed

from base import MyMongo, MongoConfig
from src.base import GlobalConfig


class MyRestore(MyMongo):
    """
    æŒ‰æ•°æ®åº“æ•´ä½“å¯¼å…¥
    """

    def __init__(self, mongo: MongoConfig, global_config: GlobalConfig):
        super().__init__(mongo, global_config)

    def restore_db(self, database: str) -> None:
        """
        é«˜æ€§èƒ½ç›´æŽ¥å¯¼å…¥ï¼šè‡ªåŠ¨è¯†åˆ«åˆ†ç‰‡é›†åˆå¹¶ç›´æŽ¥å¯¼å…¥åˆ°åŽŸå§‹é›†åˆ
        :param database: ç›®æ ‡æ•°æ®åº“å
        """
        db_dir = os.path.join(self.global_config.dump_root_path, database)
        if not os.path.exists(db_dir):
            print(f"âš ï¸ æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {db_dir}")
            return

        try:
            # èŽ·å–æ‰€æœ‰æ–‡ä»¶
            all_files = os.listdir(db_dir)

            # è¯†åˆ«åˆ†ç‰‡é›†åˆå’Œæ™®é€šé›†åˆ
            sharded_collections = {}
            normal_collections = []
            import_tasks = []

            # è¿‡æ»¤å¿½ç•¥çš„é›†åˆ
            for file in all_files:
                if file.endswith('.bson'):
                    collection_name = file.replace('.bson', '')

                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¢«å¿½ç•¥çš„é›†åˆ
                    full_name = f"{database}.{collection_name}"
                    if full_name in self.global_config.ignore_collections:
                        print(f"ðŸš« è·³è¿‡å¯¼å…¥ï¼ˆè¢«å¿½ç•¥ï¼‰: {full_name}")
                        continue

                    if '_part' in collection_name:
                        # åˆ†ç‰‡é›†åˆ
                        original_name = collection_name.split('_part')[0]
                        # æ£€æŸ¥åˆ†ç‰‡é›†åˆçš„åŽŸå§‹åç§°æ˜¯å¦è¢«å¿½ç•¥
                        original_full_name = f"{database}.{original_name}"
                        if original_full_name in self.global_config.ignore_collections:
                            print(f"ðŸš« è·³è¿‡åˆ†ç‰‡å¯¼å…¥ï¼ˆè¢«å¿½ç•¥ï¼‰: {original_full_name}")
                            continue

                        if original_name not in sharded_collections:
                            sharded_collections[original_name] = []
                        sharded_collections[original_name].append(os.path.join(db_dir, file))
                    else:
                        # æ™®é€šé›†åˆ
                        normal_collections.append(collection_name)

            # æž„å»ºæ‰€æœ‰å¯¼å…¥ä»»åŠ¡
            # åˆ†ç‰‡ä»»åŠ¡ï¼šæ¯ä¸ªåˆ†ç‰‡æ–‡ä»¶å¯¼å…¥åˆ°åŽŸå§‹é›†åˆ
            for original_name, shard_files in sharded_collections.items():
                for i, shard_file in enumerate(shard_files):
                    import_tasks.append(('sharded', original_name, shard_file))

            # å…ˆé‡å»ºåŽŸå§‹é›†åˆï¼ˆä»…é’ˆå¯¹åˆ†ç‰‡é›†åˆï¼‰
            for original_name in sharded_collections:
                self.client[database][original_name].drop()
                self.client[database].create_collection(original_name)

            # æ™®é€šä»»åŠ¡ï¼šæ¯ä¸ªæ™®é€šé›†åˆå•ç‹¬å¯¼å…¥
            for collection_name in normal_collections:
                bson_file = os.path.join(db_dir, f"{collection_name}.bson")
                if os.path.exists(bson_file):
                    import_tasks.append(('normal', collection_name, bson_file))

            if not import_tasks:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¯¼å…¥çš„æ–‡ä»¶ï¼ˆå¯èƒ½å…¨éƒ¨è¢«å¿½ç•¥æˆ–ç›®å½•ä¸ºç©ºï¼‰")
                return

            print(f"ðŸš€ å‡†å¤‡å¹¶å‘å¯¼å…¥ {len(import_tasks)} ä¸ªä»»åŠ¡ï¼Œä½¿ç”¨ {self.global_config.numParallelCollections} ä¸ªçº¿ç¨‹")

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¯¼å…¥
            print(f"ðŸ“ æ•°æ®åº“ç›®å½•: {db_dir}")
            print(f"ðŸ“Š åˆ†ç‰‡é›†åˆ: {list(sharded_collections.keys())}")
            print(f"ðŸ“Š æ™®é€šé›†åˆ: {normal_collections}")

            with ThreadPoolExecutor(max_workers=self.global_config.numParallelCollections) as executor:
                future_to_task = {}

                for task_type, target_collection, file_path in import_tasks:
                    # å¯¹äºŽæ™®é€šé›†åˆï¼Œæ€»æ˜¯ä½¿ç”¨dropï¼›å¯¹äºŽåˆ†ç‰‡ï¼Œåªæœ‰ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½¿ç”¨drop
                    future = executor.submit(self._import_single_file, database, target_collection, file_path,
                                             task_type == 'sharded')
                    future_to_task[future] = (task_type, target_collection, file_path)

                # æ”¶é›†ç»“æžœ
                completed = 0
                errors = []

                for future in as_completed(future_to_task, timeout=None):  # æ— è¶…æ—¶é™åˆ¶
                    task_type, target_collection, file_path = future_to_task[future]
                    try:
                        result = future.result()
                        completed += 1
                        print(f"âœ… é›†åˆå¯¼å…¥æˆåŠŸ: {database}: [{completed}/{len(import_tasks)}] {result}")
                    except Exception as e:
                        print(f"âŒ å¯¼å…¥å¤±è´¥ {file_path}: {e}")
                        # å¦‚æžœæ˜¯è®¤è¯å¤±è´¥ï¼Œç»™å‡ºæç¤º
                        if "authentication" in str(e).lower():
                            print("ðŸ”‘ è¯·æ£€æŸ¥ç”¨æˆ·åã€å¯†ç å’Œè®¤è¯æ•°æ®åº“è®¾ç½®")
                        elif "connection" in str(e).lower():
                            print("ðŸ”— è¯·æ£€æŸ¥MongoDBè¿žæŽ¥å‚æ•°")
                        elif "file" in str(e).lower():
                            print("ðŸ“ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæƒé™")
                        elif "timeout" in str(e).lower():
                            print("â° å‘½ä»¤æ‰§è¡Œè¶…æ—¶ï¼Œå¯å°è¯•å¢žåŠ è¶…æ—¶æ—¶é—´")
                        errors.append(f"{file_path}: {e}")

                # å¦‚æžœæœ‰é”™è¯¯ï¼Œæ±‡æ€»åŽæŠ›å‡º
                if errors:
                    raise Exception(f"å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºçŽ° {len(errors)} ä¸ªé”™è¯¯:\n" + "\n".join(errors))


        except Exception as e:
            print(f'âŒ å¯¼å…¥æ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise

    def _import_single_file(self, database: str, target_collection: str, file_path: str,
                            is_sharded: bool = False) -> str:
        """
        å¯¼å…¥å•ä¸ªæ–‡ä»¶åˆ°æŒ‡å®šé›†åˆ
        :param database: æ•°æ®åº“å
        :param target_collection: ç›®æ ‡é›†åˆå
        :param file_path: æ–‡ä»¶è·¯å¾„
        :param is_sharded: æ˜¯å¦æ˜¯åˆ†ç‰‡
        :return: å¯¼å…¥ç»“æžœæè¿°
        """
        try:
            # æž„å»ºè®¤è¯å‚æ•°
            user_append = f'--username="{self.mongo_config.username}"' if self.mongo_config.username else ''
            password_append = f'--password="{self.mongo_config.password}"' if self.mongo_config.password else ''
            auth_append = f'--authenticationDatabase=admin' if self.mongo_config.username else ''

            import_cmd = (
                f'{self.mongorestore_exe} '
                f'--host {self.mongo_config.host}:{self.mongo_config.port} '
                f'{user_append} {password_append} {auth_append} '
                f'--numParallelCollections=1 '
                f'--numInsertionWorkersPerCollection={self.global_config.numInsertionWorkersPerCollection} '
                f'--noIndexRestore '
                f'{"--drop " if not is_sharded else ""}'
                f'--db {database} '
                f'--collection {target_collection} '
                f'"{file_path}"'
            )

            self.exe_command(import_cmd, timeout=None)
            file_name = os.path.basename(file_path)
            return f"{file_name} -> {target_collection}"
        except Exception as e:
            raise Exception(f"å¯¼å…¥ {file_path} å¤±è´¥: {e}")
