import os
import platform
import re
from subprocess import Popen, PIPE, STDOUT
from typing import List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from pymongo import MongoClient

from base import Shell, Mongo, mongorestore_exe


class MyRestore(Shell):
    """
    æŒ‰æ•°æ®åº“æ•´ä½“å¯¼å…¥
    """

    def __init__(self, mongo: Mongo, num_parallel_collections: int = 4, num_insertion_workers: int = 4):
        super().__init__()
        self.mongo = mongo
        self.num_parallel_collections = num_parallel_collections
        self.num_insertion_workers = num_insertion_workers

    def restore_db(self, database: str, dump_root_path: str) -> None:
        """
        é«˜æ€§èƒ½ç›´æ¥å¯¼å…¥ï¼šè‡ªåŠ¨è¯†åˆ«åˆ†ç‰‡é›†åˆå¹¶ç›´æ¥å¯¼å…¥åˆ°åŸå§‹é›†åˆ
        :param database: ç›®æ ‡æ•°æ®åº“å
        :param dump_root_path: å¯¼å‡ºæ ¹è·¯å¾„
        """
        self.restore_db_direct(database, dump_root_path)

    def _import_single_file(self, database: str, target_collection: str, file_path: str, is_first_shard: bool = False) -> str:
        """
        å¯¼å…¥å•ä¸ªæ–‡ä»¶åˆ°æŒ‡å®šé›†åˆ
        :param database: æ•°æ®åº“å
        :param target_collection: ç›®æ ‡é›†åˆå
        :param file_path: æ–‡ä»¶è·¯å¾„
        :param is_first_shard: æ˜¯å¦æ˜¯ç¬¬ä¸€ä¸ªåˆ†ç‰‡ï¼ˆå†³å®šæ˜¯å¦dropï¼‰
        :return: å¯¼å…¥ç»“æœæè¿°
        """
        try:
            # æ„å»ºè®¤è¯å‚æ•°
            user_append = f'--username="{self.mongo.username}"' if self.mongo.username else ''
            password_append = f'--password="{self.mongo.password}"' if self.mongo.password else ''
            auth_append = f'--authenticationDatabase=admin' if self.mongo.username else ''

            import_cmd = (
                f'{mongorestore_exe} '
                f'--host {self.mongo.host}:{self.mongo.port} '
                f'{user_append} {password_append} {auth_append} '
                f'--numParallelCollections=1 '
                f'--numInsertionWorkersPerCollection={self.num_insertion_workers} '
                f'--noIndexRestore '
                f'{"--drop " if is_first_shard else ""}'
                f'--db {database} '
                f'--collection {target_collection} '
                f'"{file_path}"'
            )

            self._exe_command(import_cmd)
            file_name = os.path.basename(file_path)
            return f"{file_name} -> {target_collection}"

        except Exception as e:
            raise Exception(f"å¯¼å…¥ {file_path} å¤±è´¥: {e}")

    def restore_db_direct(self, database: str, dump_root_path: str) -> None:
        """
        é«˜æ€§èƒ½ç›´æ¥å¯¼å…¥ï¼šè‡ªåŠ¨è¯†åˆ«åˆ†ç‰‡é›†åˆå¹¶ç›´æ¥å¯¼å…¥åˆ°åŸå§‹é›†åˆ
        :param database: ç›®æ ‡æ•°æ®åº“å
        :param dump_root_path: å¯¼å‡ºæ ¹è·¯å¾„
        """
        if not dump_root_path:
            print(f"âš ï¸ æ²¡æœ‰æä¾›æ•°æ®åº“ç›®å½•è·¯å¾„")
            return

        db_dir = os.path.join(dump_root_path, database)
        if not os.path.exists(db_dir):
            print(f"âš ï¸ æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {db_dir}")
            return

        try:
            # è·å–æ‰€æœ‰æ–‡ä»¶
            all_files = os.listdir(db_dir)

            # è¯†åˆ«åˆ†ç‰‡é›†åˆå’Œæ™®é€šé›†åˆ
            sharded_collections = {}
            normal_collections = []
            import_tasks = []

            for file in all_files:
                if file.endswith('.bson'):
                    collection_name = file.replace('.bson', '')
                    if '_part' in collection_name:
                        # åˆ†ç‰‡é›†åˆ
                        original_name = collection_name.split('_part')[0]
                        if original_name not in sharded_collections:
                            sharded_collections[original_name] = []
                        sharded_collections[original_name].append(os.path.join(db_dir, file))
                    else:
                        # æ™®é€šé›†åˆ
                        normal_collections.append(collection_name)

            # æ„å»ºæ‰€æœ‰å¯¼å…¥ä»»åŠ¡
            # åˆ†ç‰‡ä»»åŠ¡ï¼šæ¯ä¸ªåˆ†ç‰‡æ–‡ä»¶å¯¼å…¥åˆ°åŸå§‹é›†åˆ
            for original_name, shard_files in sharded_collections.items():
                for i, shard_file in enumerate(shard_files):
                    is_first = (i == 0)  # åªæœ‰ç¬¬ä¸€ä¸ªåˆ†ç‰‡æ–‡ä»¶ä½¿ç”¨--drop
                    import_tasks.append(('sharded', original_name, shard_file, is_first))

            # æ™®é€šä»»åŠ¡ï¼šæ¯ä¸ªæ™®é€šé›†åˆå•ç‹¬å¯¼å…¥
            for collection_name in normal_collections:
                bson_file = os.path.join(db_dir, f"{collection_name}.bson")
                if os.path.exists(bson_file):
                    import_tasks.append(('normal', collection_name, bson_file, True))

            if not import_tasks:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¯¼å…¥çš„æ–‡ä»¶")
                return

            print(f"ğŸš€ å‡†å¤‡å¹¶å‘å¯¼å…¥ {len(import_tasks)} ä¸ªä»»åŠ¡ï¼Œä½¿ç”¨ {self.num_parallel_collections} ä¸ªçº¿ç¨‹")

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¯¼å…¥
            print(f"ğŸ“ æ•°æ®åº“ç›®å½•: {db_dir}")
            print(f"ğŸ“Š åˆ†ç‰‡é›†åˆ: {list(sharded_collections.keys())}")
            print(f"ğŸ“Š æ™®é€šé›†åˆ: {normal_collections}")

            with ThreadPoolExecutor(max_workers=self.num_parallel_collections) as executor:
                future_to_task = {}

                for task_type, target_collection, file_path, is_first in import_tasks:
                    # å¯¹äºæ™®é€šé›†åˆï¼Œæ€»æ˜¯ä½¿ç”¨dropï¼›å¯¹äºåˆ†ç‰‡ï¼Œåªæœ‰ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½¿ç”¨drop
                    should_drop = is_first and (task_type == 'sharded' or task_type == 'normal')
                    future = executor.submit(self._import_single_file, database, target_collection, file_path, should_drop)
                    future_to_task[future] = (task_type, target_collection, file_path)

                # æ”¶é›†ç»“æœ
                completed = 0
                for future in as_completed(future_to_task):
                    task_type, target_collection, file_path = future_to_task[future]
                    try:
                        result = future.result()
                        completed += 1
                        print(f"âœ… [{completed}/{len(import_tasks)}] {result}")
                    except Exception as e:
                        print(f"âŒ å¯¼å…¥å¤±è´¥ {file_path}: {e}")
                        # å¦‚æœæ˜¯è®¤è¯å¤±è´¥ï¼Œç»™å‡ºæç¤º
                        if "authentication" in str(e).lower():
                            print("ğŸ”‘ è¯·æ£€æŸ¥ç”¨æˆ·åã€å¯†ç å’Œè®¤è¯æ•°æ®åº“è®¾ç½®")
                        elif "connection" in str(e).lower():
                            print("ğŸ”— è¯·æ£€æŸ¥MongoDBè¿æ¥å‚æ•°")
                        elif "file" in str(e).lower():
                            print("ğŸ“ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæƒé™")
                        raise

            print(f'âœ… æ•°æ®åº“ {database} å¹¶å‘å¯¼å…¥å®Œæˆ')

        except Exception as e:
            print(f'âŒ ç›´æ¥å¯¼å…¥æ•°æ®åº“ {database} å¤±è´¥: {e}')
            raise
